{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Name – Rohan Rashinkar\n",
    "## Roll No – I4239\n",
    "## Division – 2\n",
    "## Practical - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Autoencoder to implement anomaly detection. Build the model by using:\n",
    "# a. Import required libraries\n",
    "# b. Upload / access the dataset\n",
    "# c. Encoder converts it into latent representation\n",
    "# d. Decoder networks convert it back to the original input\n",
    "# e. Compile the models with Optimizer, Loss, and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "RANDOM_SEED = 2021\n",
    "TEST_PCT = 0.3\n",
    "LABELS = [\"Normal\",\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for any null values\n",
    "print(\"Any nulls in the dataset\",dataset.isnull().values.any())\n",
    "print('------------')\n",
    "print(\"No. of unique labels\",len(dataset['Class'].unique()))\n",
    "print(\"Label values\",dataset.Class.unique())\n",
    "#0 is for normal credit card transcation\n",
    "#1 is for fraudulent credit card transcation\n",
    "print('------------')\n",
    "print(\"Break down of Normal and Fraud Transcations\")\n",
    "print(pd.value_counts(dataset['Class'],sort=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the imbalanced dataset\n",
    "count_classes = pd.value_counts(dataset['Class'],sort=True)\n",
    "count_classes.plot(kind='bar',rot=0)\n",
    "plt.xticks(range(len(dataset['Class'].unique())),dataset.Class.unique())\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "dataset['Time'] = sc.fit_transform(dataset['Time'].values.reshape(-1,1))\n",
    "dataset['Amount'] = sc.fit_transform(dataset['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dataset.values\n",
    "#The last element contains if the transcation is normal which is represented by 0 and if fraud then 1\n",
    "labels = raw_data[:,-1]\n",
    "#The other data points are the electrocadriogram data\n",
    "data = raw_data[:,0:-1]\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size = 0.2,random_state =2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n",
    "train_data = tf.cast(train_data,tf.float32)\n",
    "test_data = tf.cast(test_data,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "\n",
    "#Creating normal and fraud datasets\n",
    "normal_train_data = train_data[~train_labels]\n",
    "normal_test_data = test_data[~test_labels]\n",
    "fraud_train_data = train_data[train_labels]\n",
    "fraud_test_data = test_data[test_labels]\n",
    "\n",
    "print(\"No. of records in Fraud Train Data=\",len(fraud_train_data))\n",
    "print(\"No. of records in Normal Train Data=\",len(normal_train_data))\n",
    "print(\"No. of records in Fraud Test Data=\",len(fraud_test_data))\n",
    "print(\"No. of records in Normal Test Data=\",len(normal_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 64\n",
    "input_dim = normal_train_data.shape[1]\n",
    "#num of columns,30\n",
    "encoding_dim = 14\n",
    "hidden_dim1 = int(encoding_dim / 2)\n",
    "hidden_dim2 = 4\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "\n",
    "#Encoder\n",
    "encoder = tf.keras.layers.Dense(encoding_dim,activation=\"tanh\",activity_regularizer = tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
    "encoder = tf.keras.layers.Dropout(0.2)(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim1,activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim2,activation=tf.nn.leaky_relu)(encoder)\n",
    "\n",
    "#Decoder\n",
    "decoder = tf.keras.layers.Dense(hidden_dim1,activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dropout(0.2)(decoder)\n",
    "decoder = tf.keras.layers.Dense(encoding_dim,activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(input_dim,activation='tanh')(decoder)\n",
    "\n",
    "#Autoencoder\n",
    "autoencoder = tf.keras.Model(inputs = input_layer,outputs = decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",mode='min',monitor='val_loss',verbose=2,save_best_only=True)\n",
    "\n",
    "#Define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=11,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],loss= 'mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(normal_train_data,normal_train_data,epochs = nb_epoch,\n",
    "    batch_size = batch_size,shuffle = True,\n",
    "    validation_data = (test_data,test_data),\n",
    "    verbose=1,\n",
    "    callbacks = [cp,early_stop]).history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'],linewidth = 2,label = 'Train')\n",
    "plt.plot(history['val_loss'],linewidth = 2,label = 'Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_predictions = autoencoder.predict(test_data)\n",
    "mse = np.mean(np.power(test_data - test_x_predictions, 2),axis = 1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error':mse,'True_class':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 50\n",
    "groups = error_df.groupby('True_class')\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name,group in groups:\n",
    "    ax.plot(group.index,group.Reconstruction_error,marker='o',ms = 3.5,linestyle='',label = \"Fraud\" if name==1 else \"Normal\")\n",
    "\n",
    "ax.hlines(threshold_fixed,ax.get_xlim()[0],ax.get_xlim()[1],colors=\"r\",zorder=100,label=\"Threshold\")\n",
    "ax.legend()\n",
    "plt.title(\"Reconstructions error for normal and fraud data\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 52\n",
    "pred_y = [1 if e > threshold_fixed else 0\n",
    "            for e in\n",
    "        error_df.Reconstruction_error.values]\n",
    "error_df['pred'] = pred_y\n",
    "conf_matrix = confusion_matrix(error_df.True_class,pred_y)\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "sns.heatmap(conf_matrix,xticklabels = LABELS,yticklabels = LABELS,annot = True,fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel(\"True class\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.show()\n",
    "\n",
    "#Print Accuracy,Precision and Recall\n",
    "print(\"Accuracy :\",accuracy_score(error_df['True_class'],error_df['pred']))\n",
    "print(\"Recall :\",recall_score(error_df['True_class'],error_df['pred']))\n",
    "print(\"Precision :\",precision_score(error_df['True_class'],error_df['pred']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
